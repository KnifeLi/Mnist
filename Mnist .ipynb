{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:green\">Welcome to Tensorflow Tutorial</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import tensorflow as tf\n",
    "from tensorflow.contrib import slim \n",
    "from tensorflow.python.ops import init_ops\n",
    "tf.logging.set_verbosity('ERROR')\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "from matplotlib.pyplot import imshow\n",
    "import os\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "# number 1 to 10 data\n",
    "mnist = input_data.read_data_sets('MNIST_data', one_hot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# <span style=\"color:green\">Awesome! Now, you get mnist dataset!</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fef17d3bef0>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fef239c0f60>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#show image\n",
    "batch_xs, batch_ys = mnist.train.next_batch(1)\n",
    "batch_xs=(batch_xs.reshape(28,28)*255).astype(np.uint)\n",
    "imshow(batch_xs, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_ys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#define input tensor and Variable\n",
    "xs = tf.placeholder(tf.float32, [None, 784]) # 28x28\n",
    "ys = tf.placeholder(tf.float32, [None, 10])\n",
    "\n",
    "keep_prob_tensor = tf.placeholder(tf.float32)  #dropout \n",
    "learning_rate_tensor=tf.placeholder(tf.float32)\n",
    "global_step = tf.Variable(0, name='global_step', trainable=False)\n",
    "x_image = tf.reshape(xs, [-1, 28, 28, 1])\n",
    "define_model=False\n",
    "log_path='/data4/DR/Tutorial/log'"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Tensorflow default input (2D) shape is [batch size,height,width,channel]\n",
    "Tensorflow default input (3D) shape is [batch size,depth,height,width,channel]\n",
    "Label=[batch size,label file]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_ys"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Label must be a array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:green\">Now! build your own model!</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.variable_scope(\"Tensorflow_Tutorial\") as scope:\n",
    "    if define_model==True:\n",
    "        tf.get_variable_scope().reuse_variables()\n",
    "    #start define model\n",
    "    #convolution layer-output 32 kernals, kernal size 5 X 5, stride 2,activation_fn=relu\n",
    "    net=slim.conv2d(x_image,32,[5,5],2,weights_initializer=init_ops.truncated_normal_initializer(stddev=0.1)\n",
    "                    ,biases_initializer=init_ops.Constant(0.1),\n",
    "                    activation_fn=tf.nn.relu,padding='SAME',scope='conv_1')\n",
    "    #pool layer-max pool with 2 X 2\n",
    "    net=slim.max_pool2d(net,[2,2],scope='max_pool_1')\n",
    "    net=slim.conv2d(net,64,[5,5],2,weights_initializer=init_ops.truncated_normal_initializer(stddev=0.1),\n",
    "                    biases_initializer=init_ops.Constant(0.1),scope='conv_2')\n",
    "    net=slim.max_pool2d(net,[2,2],scope='max_pool_2')\n",
    "    #fully connected layer-output 1024\n",
    "    net=slim.fully_connected(net,1024,scope='fc_1',weights_initializer=init_ops.truncated_normal_initializer(stddev=0.1),\n",
    "                            biases_initializer=init_ops.Constant(0.1))\n",
    "    #flatten\n",
    "    net=slim.flatten(net, scope='PreLogitsFlatten')\n",
    "    net=tf.nn.dropout(net,keep_prob_tensor)\n",
    "    #result without softmax\n",
    "    logit=slim.fully_connected(net,10,scope='fc_2',weights_initializer=init_ops.truncated_normal_initializer(stddev=0.1),\n",
    "                              biases_initializer=init_ops.Constant(0.1))\n",
    "    \n",
    "    define_model=True\n",
    "    \n",
    "    #define loss\n",
    "    loss=slim.losses.softmax_cross_entropy(logit,ys)\n",
    "    #define optimizer for training\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate_tensor)\n",
    "    #define train operator\n",
    "    train_op = slim.learning.create_train_op(loss, optimizer,global_step)\n",
    "    \n",
    "    prediction=tf.arg_max(logit,1)\n",
    "    accuracy=slim.metrics.accuracy(tf.arg_max(logit,1),tf.arg_max(ys,1))\n",
    "    \n",
    "    #define summary for tensorboard\n",
    "    tf.summary.scalar('Loss',loss)\n",
    "    tf.summary.scalar('accuracy',accuracy)\n",
    "    summary_op=tf.summary.merge_all()\n",
    "    #get variables which need to be initialed \n",
    "    variables_for_init=tf.global_variables_initializer()\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "config = tf.ConfigProto()\n",
    "config.gpu_options.per_process_gpu_memory_fraction = 0.1  #0.1 =GPU_memory usage\n",
    "sess = tf.Session(config=config) #start Session \n",
    "#Session.run(require tensorflow run something  )\n",
    "sess.run(variables_for_init)     #initiaal variables \n",
    "writer_master = tf.summary.FileWriter(log_path, sess.graph)   #define summary writer for tensorboard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:green\">Must initial variables before anything!</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#sess = tf.Session()\n",
    "#sess.run(variables_for_init)\n",
    "#writer_master = tf.summary.FileWriter(log_path, sess.graph)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:green\">Tuning parameters!</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Steps=2000\n",
    "learning_rate=0.0001\n",
    "keep_prob=0.5\n",
    "valid=100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:green\">Start training!</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss:3.80257 Accuracy:0.1025\n",
      "train_loss:2.30768 Accuracy:0.111\n",
      "train_loss:2.23507 Accuracy:0.1839\n",
      "train_loss:1.81147 Accuracy:0.3603\n",
      "train_loss:1.555 Accuracy:0.5626\n",
      "train_loss:0.80971 Accuracy:0.6956\n",
      "train_loss:0.61118 Accuracy:0.7672\n",
      "train_loss:0.629698 Accuracy:0.7988\n",
      "train_loss:0.387269 Accuracy:0.8721\n",
      "train_loss:0.278101 Accuracy:0.8953\n",
      "train_loss:0.348841 Accuracy:0.9139\n",
      "train_loss:0.21623 Accuracy:0.9224\n",
      "train_loss:0.138004 Accuracy:0.9285\n",
      "train_loss:0.350527 Accuracy:0.9368\n",
      "train_loss:0.268281 Accuracy:0.9355\n",
      "train_loss:0.151027 Accuracy:0.9379\n",
      "train_loss:0.280224 Accuracy:0.945\n",
      "train_loss:0.216538 Accuracy:0.9493\n",
      "train_loss:0.319134 Accuracy:0.9518\n",
      "train_loss:0.248271 Accuracy:0.9526\n"
     ]
    }
   ],
   "source": [
    "for step in range(Steps):\n",
    "    batch_xs, batch_ys = mnist.train.next_batch(100)\n",
    "    #session can run multi tensors -> sess.run([tensors,tensors])\n",
    "    #session can run single tensors -> sess.run([tensor])\n",
    "    #feed_dict -> assign data to tensor \n",
    "    '''\n",
    "    useless  <- train_op\n",
    "    train_loss  <-  loss\n",
    "    xs  <- batch_xs\n",
    "    ys  <-  batch_ys\n",
    "    '''\n",
    "    useless,train_loss=sess.run([train_op,loss], feed_dict={xs: batch_xs, ys: batch_ys, \n",
    "                                    keep_prob_tensor: keep_prob,learning_rate_tensor:learning_rate})\n",
    "    if step % valid == 0:\n",
    "        accuracy_,summary_=sess.run([accuracy,summary_op,], feed_dict={xs: mnist.test.images, ys: mnist.test.labels, \n",
    "                                      keep_prob_tensor: keep_prob,learning_rate_tensor:learning_rate})\n",
    "        print ('train_loss:'+str(train_loss),'Accuracy:'+str(accuracy_))   \n",
    "        #write summary to tensorboard\n",
    "        #step is X\n",
    "        writer_master.add_summary(summary_,step)\n",
    "        #force writer write report to tensorboard\n",
    "        writer_master.flush()\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_xs, batch_ys = mnist.train.next_batch(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#predict the result\n",
    "prediction_=sess.run(prediction, feed_dict={xs: batch_xs, \n",
    "                                    keep_prob_tensor: keep_prob,learning_rate_tensor:learning_rate})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:green\">Now! Save your own model!</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/data4/DR/Tutorial/log/model.ckpt'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#define saver for save model variables from sess\n",
    "Saver=tf.train.Saver()\n",
    "model_path=os.path.join(log_path,'model.ckpt')\n",
    "Saver.save(sess,model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#restore model variables for sess\n",
    "# you must initial model variables before restore\n",
    "Saver.restore(sess,model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#type following instruction on the command line to run tensorboard\n",
    "tensorboard --logdir=/data4/DR/Tutorial/log"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
